{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Business Objective:** \nThe difference between the use of Cyclistic bikes between Casual riders and annual members in order to increase the company revenue by increasing annual members.\n\n\n# **Description of Data Source:**\nThe data is available and regularly updated in the zip format file on the website <Index of bucket \"divvy-tripdata\">. The data for the past 12 months from April 2023 to May 2020 was downloaded from this website and arranged in a separate folder in my Drive, also a copy of the original data is made in order to refer to later steps in the analysis if needed. The data is organized with the ride_id as the field name and with respect to this id different details of the ride such as start time, end time, starting and ending station of the trip, and also the member type also mentioned whether the member is an annual member or casual user. After filtering and viewing data it can be seen that starting or ending station names or latitude and longitude values of a few rides are missing. Since the data is provided from a trusted source and also the privacy of the user is maintained by not showing their sensitive credentials such as name, credit card number, etc. so the data integrity is maintained for initial level analysis.\n\n# **Steps Taken for Cleaning and Manipulation of Data:**\n* First of all the data is checked in Excel for any missing or wrong value within all the columns and it was found that a significant amount of values are missing in columns like start_station_name, end_station_name, start_lat, start long, end_lat, end_long. These data values were not omitted as they were making a significant amount of data and also these data points were not creating a great impact on our analysis.\n* Then the days_of_week were found in Excel using the text function for each month. \n* After loading the necessary libraries, all these CSV files are uploaded into the R environment for further analysis, I chose Rstudio as it supports this much amount of large data.\n* After that, all the data for 12 months are then aggregated into one table i.e., ‘all_trips’.\n\n\n","metadata":{}},{"cell_type":"code","source":"library(tidyverse)\nlibrary(ggplot2)\nlibrary(lubridate)\ninstall.packages(\"farver\")\ngetwd()\n#setwd(\"E:/Coursera Data Science Tasks/Google Capstone/Week 2/Edited data of cycle/Edited csv\")\nlibrary(readr)\nApril_2023<- read_csv(\"April 2023.csv\")\nMarch_2023<- read_csv(\"March 2023.csv\")\nFeb_2023 <- read_csv(\"Feb 2023.csv\")\nJan_2023 <- read_csv(\"Jan 2023.csv\")\nDec_2022 <- read_csv(\"Dec 2022.csv\")\nNov_2022 <- read_csv(\"Nov 2022.csv\")\nOct_2022 <- read_csv(\"Oct 2022.csv\")\nSept_2022 <- read_csv(\"Sept 2022.csv\")\nAug_2022 <- read_csv(\"Aug 2022.csv\")\nJul_2022 <- read_csv(\"Jul 2022.csv\")\nJun_2022 <- read_csv(\"Jun 2022.csv\")\nMay_2022 <- read_csv(\"May 2022.csv\")\ncolnames(March_2023)\nstr(April_2023)\n##str(March_2023)\n##str(Feb_2023)\nlibrary(hms)\nApril_2023 <-mutate(April_2023,starting_time = as_hms(starting_time))\nApril_2023 <-mutate(April_2023,ending_time = as_hms(ending_time))\nstr(April_2023)\nstr(March_2023)\n\nall_trips <- bind_rows(April_2023,March_2023)\nstr(April_2023)\nall_trips <-bind_rows(all_trips,Feb_2023)\nall_trips <- bind_rows(all_trips,Jan_2023,Dec_2022,Nov_2022,Oct_2022,Sept_2022,Jul_2022,Jun_2022,May_2022)\nstr(all_trips)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T06:38:44.611499Z","iopub.execute_input":"2023-06-16T06:38:44.613745Z","iopub.status.idle":"2023-06-16T06:39:35.590777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The started_date formatted into mdy_hm format for further analysis\n* Then with the help of ymd library months and years were found separately","metadata":{}},{"cell_type":"code","source":"all_trips$starting_date <- mdy(all_trips$starting_date)\nall_trips$months<- months(ymd(all_trips$starting_date))\nstr(all_trips)\nall_trips$years<- year((ymd(all_trips$starting_date)))\nall_trips$days<- day((ymd(all_trips$starting_date)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* After correcting the format from string to mdy_hm of started_at and ended_at values ride_length was calculated\n* The ride_length i.e., duration of ride was calculated by subtracting starting and ending time using difftime()  function.","metadata":{}},{"cell_type":"code","source":"all_trips$started_at <- mdy_hm(all_trips$started_at)\nall_trips$ended_at <- mdy_hm(all_trips$ended_at)\nall_trips$ride_length <- as.numeric(difftime(all_trips$ended_at,all_trips$started_at, units = \"secs\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Data points with negative ride_length are omitted as starting time cannot be less than the ending time, but before omitting a copy of data set was made as data is being removed.\n* So now the new table all_trips_v2 is formed and again checked for any na values.\n","metadata":{}},{"cell_type":"code","source":"str(all_trips)\nis.numeric(all_trips$ride_length)\nall_trips_v2 <- all_trips[!( all_trips$ride_length<=0),]\nstr(all_trips)\nView(all_trips_v2)\nsum(is.na(all_trips_v2$ride_length))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Performing Arithmetic Calculations:**\n* First of all max, min, mean, and median of ride length were calculated. \n* Further, different correlation between both type of users and the number of rides on each day was found and viewed.\n* Similarly correlation between both type of users and average_ride length each day was calculated and viewed.\n* Preference of users for the type of bike they use more often was found and viewed.\n* Overall yearly analysis is done by finding out the number of rides used by each user in different quarters of the year\n","metadata":{}},{"cell_type":"markdown","source":"# **Summary of Analysis:**\n* The summary for max, min, mean, and median were found out as below:","metadata":{}},{"cell_type":"code","source":"mean(all_trips_v2$ride_length)\nmedian(all_trips_v2$ride_length)\nmax(all_trips_v2$ride_length)\nmin(all_trips_v2$ride_length)\n\nsummary(all_trips_v2$ride_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The mean, max, min and median was calculated again with respect to the member type.","metadata":{}},{"cell_type":"code","source":"aggregate(all_trips_v2$ride_length~all_trips_v2$member_casual,FUN = mean)\naggregate(all_trips_v2$ride_length~all_trips_v2$member_casual,FUN = median)\naggregate(all_trips_v2$ride_length~all_trips_v2$member_casual,FUN = max)\naggregate(all_trips_v2$ride_length~all_trips_v2$member_casual,FUN = min)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now calculating average ride duration for each day for both the customer.","metadata":{}},{"cell_type":"code","source":"#checking average ride length for each day of members and casual users\naggregate(all_trips_v2$ride_length~all_trips_v2$member_casual+all_trips_v2$day_of_weeks, FUN=mean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Since the days were not sorted out so we then sorted it and again calculated the average ride duration.","metadata":{}},{"cell_type":"code","source":"#Now sordering days of the week.\nall_trips_v2$day_of_weeks <- ordered(all_trips_v2$day_of_weeks, levels = c('Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'))\n\n#Again checking the avg ride time of each day of both type of customers\naggregate(all_trips_v2$ride_length~all_trips_v2$member_casual+all_trips_v2$day_of_weeks, FUN = mean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now calculating average ride length in more appropiate way.","metadata":{}},{"cell_type":"code","source":"#checking average rides on every day for both type of customer\nall_trips_v2 %>%\n  group_by(member_casual,day_of_weeks)%>%\n  summarise(number_of_rides = n(),average_duration = mean(ride_length))%>%\n  arrange(member_casual, day_of_weeks)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now dividing the years in 4 Quarters for further analysis","metadata":{}},{"cell_type":"code","source":"all_trips_v2$quaterly_dates <-as.numeric( quarter(all_trips_v2$ended_at))\nView(all_trips_v2)\n#dividing in quarters\n\nfirst_quater <-  filter(all_trips_v2, quaterly_dates==\"1\")\n#View(first_quater)\nsecond_quater <-  filter(all_trips_v2, quaterly_dates==\"2\")\n#View(second_quater)\nthird_quater <-  filter(all_trips_v2, quaterly_dates==\"3\")\n#View(third_quater)\nfourth_quater <-  filter(all_trips_v2, quaterly_dates==\"4\")\n#View(fourth_quater)\n#number of rides\ncount_of_1st_quater <- count(first_quater)\n#View(count_of_1st_quater)\ncount_of_2nd_quater <- count(second_quater)\ncount_of_3rd_quater <- count(third_quater)\ncount_of_4th_quater <- count(fourth_quater)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now we will be visualizing data with different perspectives using ggplot2 commands.\n* Firstly, we will be viewing number of rides for each type of user.","metadata":{}},{"cell_type":"code","source":"#Let's visualize the number of rides everyday for both customers\nall_trips_v2 %>%\n  group_by(member_casual,day_of_weeks)%>%\n  summarise(number_of_rides = n(),average_duration = mean(ride_length))%>%\n  arrange(member_casual, day_of_weeks)%>%\n  ggplot(aes(x=day_of_weeks, y = number_of_rides, fill = member_casual))+geom_col(position = \"dodge\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now we will see the average rides of each customer on each day.","metadata":{}},{"cell_type":"code","source":"#Now we will see graph of average ride on each day for both customers\nall_trips_v2 %>%\n  group_by(member_casual,day_of_weeks)%>%\n  summarise(number_of_rides = n(),average_duration = mean(ride_length))%>%\n  arrange(member_casual, day_of_weeks)%>%\n  ggplot(aes(x=day_of_weeks, y = average_duration, fill = member_casual))+geom_col(position = \"dodge\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Finding out the number of rides of each customer on in different quarters of the year.","metadata":{}},{"cell_type":"code","source":"#viewing number of rides of member and casual w.r.t types of member\nall_trips_v2%>%\n  group_by(member_casual, quaterly_dates)%>%\n  summarise(number_of_rides=n(), member_casual)%>%\n  arrange(member_casual, quaterly_dates)%>%\n  ggplot(aes(x = quaterly_dates , y = number_of_rides , fill = member_casual ))+geom_col(position = \"dodge\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Also as we are having different bike types therefore now finding out the ride preferences of each user.","metadata":{}},{"cell_type":"code","source":"#now viewing preferance of customers w.r.t bike type\n  all_trips_v2%>%\n    group_by(member_casual, rideable_type)%>%\n    summarise(number_of_rides=n(), member_casual)%>%\n    arrange(member_casual, rideable_type)%>%\n    ggplot(aes(x = rideable_type , y = number_of_rides , fill = member_casual ))+geom_col(position = \"dodge\")\n  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TOP THREE RECOMMENDATIONS:**\nBased on the above findings my top 3 recommendations would be.\n\n* Since casual users use bike more oftenly on weekends so we can run marketing campaigns by encouraging the use of bikes not only for leisure purpose on weekends but also for daily day commute by raising awareness about the environmental and health benefits when using cycle. Also, we can introduce a discount for the weekdays.\n\n* As we can see that the average ride duration for casual users on each is interestingly more than member users, so we can attract these casual users by limiting their usage and they will eventually have to take the membership to ride for long duration\n \n* In order to increase membership of casual members we can target them during in Q1 and Q4 as they use bikes almost half then the member user as these months are cold. We can have a discount for winter times and raise awareness of exercise in winter.\n","metadata":{}},{"cell_type":"markdown","source":"# **LIMITATIONS WITH DATA AND IT'S IMPACT:**\n\nThe limitations was of:\n* Missing station names of starting and ending end, with the help of which we could have find the most prominent stations.\n* The age and gender information missing, with which we could have targeted specific audience according to insights.","metadata":{}}]}